}
#stp1 <- proc.time() - st1
#strk1 <<- strk1 + stp1[3]
# Reduce dataframe to eliminate columns with the same NA locations
if(nrow(df_reduced) > 0){
if(sum(df_reduced) > 0){
#st2 <- proc.time()
dups <- which(!duplicated(apply(df_reduced, 2, digest)))
dup_names <- names(df_reduced)[dups]
# subset dups to avoid repeat scenarios
sub_dups <- dups[which(dups > select_var_cut)]
sub_dup_names <- names(df_reduced)[sub_dups]
#stp2 <- proc.time() - st2
#strk2 <<- strk2 + stp2[3]
#st3 <- proc.time()
df_reduced <- data.frame(df_reduced[,dups])
#message("reduced df number of columns ", ncol(df_reduced))
#message("reduced df number of rows ", nrow(df_reduced))
names(df_reduced) <- dup_names
# Get list of new available selections
new_pick_idx <- which(colSums(df_reduced)>0)
new_pick_names <- names(df_reduced)[new_pick_idx]
# Subset new picks to only include sub_dup indices
sub_pick_idx <- which(new_pick_names %in% sub_dup_names)
new_pick_names <- new_pick_names[sub_pick_idx]
new_pick_idx <- new_pick_idx[sub_pick_idx]
#stp3 <- proc.time() - st3
#strk3 <<- strk3 + stp3[3]
#st4 <- proc.time()
orig_pick_idx <- which(orig_names %in% new_pick_names)
# Add new selections to tail selections
#stp4 <- proc.time() - st4
#strk4 <<- strk4 + stp4[3]
#st5 <- proc.time()
pick_adds <- mapply(function(x){list(sort(c(var_tail, x)))},orig_pick_idx)
pick_lu <- mapply(function(x){paste(sort(c(var_tail, x)), collapse = '')},orig_pick_idx)
#pick_lu <- mapply(function(x){paste(sort(c(var_tail, x)), collapse = '')},orig_pick_idx)
# Check for selections which already exist
#stp5 <- proc.time() - st5
#strk5 <<- strk5 + stp5[3]
#st6 <- proc.time()
ignore_idx <- which(pick_lu %in% pick_lu_list)
if(length(ignore_idx) > 0){
pick_adds <- pick_adds[-ignore_idx]
new_pick_idx <- new_pick_idx[-ignore_idx]
pick_lu <- pick_lu[-ignore_idx]
}
#stp6 <<- proc.time() - st6
#strk6 <<- strk6 + stp6[3]
# Print out intermmediate timing results
#lpl <- length(pick_list)
#if(lpl > ch){
#    message("Pick list length is around ", lpl)
#    message("Time 1 is ", strk1)
#    message("Time 2 is ", strk2)
#    message("Time 3 is ", strk3)
#    message("Time 4 is ", strk4)
#    message("Time 5 is ", strk5)
#    message("Time 6 is ", strk6)
#    message("Time 7 is ", strk7)
#    message("Time 8 is ", strk8)
#    message('')
#   ch <<- ch + 2500
#}
# Add unique new selections to pick list
if(length(pick_adds) > 0){
#st7 <- proc.time()
pick_list <- c(pick_list, pick_adds)
#stp7 <- proc.time() - st7
#strk7 <<- strk7 + stp7[3]
#st8 <- proc.time()
#pick_lu_list <- union(pick_lu_list, pick_lu)
pick_lu_list <- c(pick_lu_list, pick_lu)
#pick_lu_list <- pick_lu_list +
#stp8 <- proc.time() - st8
#strk8 <<- strk8 + stp8[3]
# For remaining new picks, rerun function
#foreach(idx = 1:length(pick_adds), .packages = 'digest') %dopar% {
for(idx in 1:length(pick_adds)){
result <- nanal.reduce5(df_reduced, new_pick_idx[idx], pick_adds[[idx]], pick_list, pick_lu_list, F, orig_names)
pick_list <- result[[1]]
pick_lu_list <- result[[2]]
}
}
}
}
list(pick_list, pick_lu_list)
}
df_test_reduce_list_5 <- nanal.reduce5(df_test)[[1]]
df_test_reduce_list_4 <- nanal.reduce4(df_test)[[1]]
df_test_reduce_list_4
df_test_reduce_list_5
df_test_na_scores_4 <- nanal.score(df_test, df_test_reduce_list_4, 10)
df_test_na_scores_5 <- nanal.score(df_test, df_test_reduce_list_5, 10)
View(df_test_na_scores_4)
View(df_test_na_scores_5)
nanal.reduce5 <- function(df, selected_var = NA, var_tail = NA, pick_list = list(), pick_lu_list = c(), start_trg = T, orig_names = NA){
if(start_trg == T){
orig_names <- names(df)
df <- data.frame(is.na(df)*1)
}
#st1 <- proc.time()
if(is.na(selected_var)){
df_reduced <- df
select_var_cut <- 0
}else{
df_reduced <- df[df[, selected_var]==0,]
select_var_cut <- selected_var
}
#stp1 <- proc.time() - st1
#strk1 <<- strk1 + stp1[3]
# Reduce dataframe to eliminate columns with the same NA locations
if(nrow(df_reduced) > 0){
if(sum(df_reduced) > 0){
#st2 <- proc.time()
dups <- which(!duplicated(apply(df_reduced, 2, digest)))
dup_names <- names(df_reduced)[dups]
# subset dups to avoid repeat scenarios
sub_dups <- dups[which(dups > select_var_cut)]
sub_dup_names <- names(df_reduced)[sub_dups]
#stp2 <- proc.time() - st2
#strk2 <<- strk2 + stp2[3]
#st3 <- proc.time()
df_reduced <- data.frame(df_reduced[,dups])
#message("reduced df number of columns ", ncol(df_reduced))
#message("reduced df number of rows ", nrow(df_reduced))
names(df_reduced) <- dup_names
# Get list of new available selections
new_pick_idx <- which(colSums(df_reduced)>0)
new_pick_names <- names(df_reduced)[new_pick_idx]
# Subset new picks to only include sub_dup indices
sub_pick_idx <- which(new_pick_names %in% sub_dup_names)
new_pick_names <- new_pick_names[sub_pick_idx]
new_pick_idx <- new_pick_idx[sub_pick_idx]
#stp3 <- proc.time() - st3
#strk3 <<- strk3 + stp3[3]
#st4 <- proc.time()
orig_pick_idx <- which(orig_names %in% new_pick_names)
# Add new selections to tail selections
#stp4 <- proc.time() - st4
#strk4 <<- strk4 + stp4[3]
#st5 <- proc.time()
pick_adds <- mapply(function(x){list(sort(c(var_tail, x)))},orig_pick_idx)
pick_lu <- mapply(function(x){paste(sort(c(var_tail, x)), collapse = '')},orig_pick_idx)
#pick_lu <- mapply(function(x){paste(sort(c(var_tail, x)), collapse = '')},orig_pick_idx)
# Check for selections which already exist
#stp5 <- proc.time() - st5
#strk5 <<- strk5 + stp5[3]
#st6 <- proc.time()
#ignore_idx <- which(pick_lu %in% pick_lu_list)
#if(length(ignore_idx) > 0){
#    pick_adds <- pick_adds[-ignore_idx]
#    new_pick_idx <- new_pick_idx[-ignore_idx]
#    pick_lu <- pick_lu[-ignore_idx]
#}
#stp6 <<- proc.time() - st6
#strk6 <<- strk6 + stp6[3]
# Print out intermmediate timing results
#lpl <- length(pick_list)
#if(lpl > ch){
#    message("Pick list length is around ", lpl)
#    message("Time 1 is ", strk1)
#    message("Time 2 is ", strk2)
#    message("Time 3 is ", strk3)
#    message("Time 4 is ", strk4)
#    message("Time 5 is ", strk5)
#    message("Time 6 is ", strk6)
#    message("Time 7 is ", strk7)
#    message("Time 8 is ", strk8)
#    message('')
#   ch <<- ch + 2500
#}
# Add unique new selections to pick list
if(length(pick_adds) > 0){
#st7 <- proc.time()
pick_list <- c(pick_list, pick_adds)
#stp7 <- proc.time() - st7
#strk7 <<- strk7 + stp7[3]
#st8 <- proc.time()
#pick_lu_list <- union(pick_lu_list, pick_lu)
pick_lu_list <- c(pick_lu_list, pick_lu)
#pick_lu_list <- pick_lu_list +
#stp8 <- proc.time() - st8
#strk8 <<- strk8 + stp8[3]
# For remaining new picks, rerun function
#foreach(idx = 1:length(pick_adds), .packages = 'digest') %dopar% {
for(idx in 1:length(pick_adds)){
result <- nanal.reduce5(df_reduced, new_pick_idx[idx], pick_adds[[idx]], pick_list, pick_lu_list, F, orig_names)
pick_list <- result[[1]]
pick_lu_list <- result[[2]]
}
}
}
}
list(pick_list, pick_lu_list)
}
df_test_reduce_list_5 <- nanal.reduce5(df_test)[[1]]
df_test_reduce_list_5 <- nanal.reduce5(df_test)[[1]]
df_test_na_scores_5 <- nanal.score(df_test, df_test_reduce_list_5, 10)
View(df_test_na_scores_5)
nanal.reduce5 <- function(df, selected_var = NA, var_tail = NA, pick_list = list(), pick_lu_list = c(), start_trg = T, orig_names = NA){
if(start_trg == T){
orig_names <- names(df)
df <- data.frame(is.na(df)*1)
}
#st1 <- proc.time()
if(is.na(selected_var)){
df_reduced <- df
select_var_cut <- 0
}else{
df_reduced <- df[df[, selected_var]==0,]
select_var_cut <- selected_var
}
#stp1 <- proc.time() - st1
#strk1 <<- strk1 + stp1[3]
# Reduce dataframe to eliminate columns with the same NA locations
if(nrow(df_reduced) > 0){
if(sum(df_reduced) > 0){
#st2 <- proc.time()
dups <- which(!duplicated(apply(df_reduced, 2, digest)))
dup_names <- names(df_reduced)[dups]
# subset dups to avoid repeat scenarios
sub_dups <- dups[which(dups > select_var_cut)]
sub_dup_names <- names(df_reduced)[sub_dups]
#stp2 <- proc.time() - st2
#strk2 <<- strk2 + stp2[3]
#st3 <- proc.time()
df_reduced <- data.frame(df_reduced[,dups])
#message("reduced df number of columns ", ncol(df_reduced))
#message("reduced df number of rows ", nrow(df_reduced))
names(df_reduced) <- dup_names
# Get list of new available selections
new_pick_idx <- which(colSums(df_reduced)>0)
new_pick_names <- names(df_reduced)[new_pick_idx]
# Subset new picks to only include sub_dup indices
sub_pick_idx <- which(new_pick_names %in% sub_dup_names)
new_pick_names <- new_pick_names[sub_pick_idx]
new_pick_idx <- new_pick_idx[sub_pick_idx]
#stp3 <- proc.time() - st3
#strk3 <<- strk3 + stp3[3]
#st4 <- proc.time()
orig_pick_idx <- which(orig_names %in% new_pick_names)
# Add new selections to tail selections
#stp4 <- proc.time() - st4
#strk4 <<- strk4 + stp4[3]
#st5 <- proc.time()
pick_adds <- mapply(function(x){list(sort(c(var_tail, x)))},orig_pick_idx)
pick_lu <- mapply(function(x){paste(sort(c(var_tail, x)), collapse = '')},orig_pick_idx)
#pick_lu <- mapply(function(x){paste(sort(c(var_tail, x)), collapse = '')},orig_pick_idx)
# Check for selections which already exist
#stp5 <- proc.time() - st5
#strk5 <<- strk5 + stp5[3]
#st6 <- proc.time()
ignore_idx <- which(pick_lu %in% pick_lu_list)
if(length(ignore_idx) > 0){
pick_adds <- pick_adds[-ignore_idx]
new_pick_idx <- new_pick_idx[-ignore_idx]
pick_lu <- pick_lu[-ignore_idx]
}
#stp6 <<- proc.time() - st6
#strk6 <<- strk6 + stp6[3]
# Print out intermmediate timing results
#lpl <- length(pick_list)
#if(lpl > ch){
#    message("Pick list length is around ", lpl)
#    message("Time 1 is ", strk1)
#    message("Time 2 is ", strk2)
#    message("Time 3 is ", strk3)
#    message("Time 4 is ", strk4)
#    message("Time 5 is ", strk5)
#    message("Time 6 is ", strk6)
#    message("Time 7 is ", strk7)
#    message("Time 8 is ", strk8)
#    message('')
#   ch <<- ch + 2500
#}
# Add unique new selections to pick list
if(length(pick_adds) > 0){
#st7 <- proc.time()
pick_list <- c(pick_list, pick_adds)
#stp7 <- proc.time() - st7
#strk7 <<- strk7 + stp7[3]
#st8 <- proc.time()
#pick_lu_list <- union(pick_lu_list, pick_lu)
pick_lu_list <- c(pick_lu_list, pick_lu)
#pick_lu_list <- pick_lu_list +
#stp8 <- proc.time() - st8
#strk8 <<- strk8 + stp8[3]
# For remaining new picks, rerun function
#foreach(idx = 1:length(pick_adds), .packages = 'digest') %dopar% {
for(idx in 1:length(pick_adds)){
result <- nanal.reduce5(df_reduced, new_pick_idx[idx], pick_adds[[idx]], pick_list, pick_lu_list, F, orig_names)
pick_list <- result[[1]]
pick_lu_list <- result[[2]]
}
}
}
}
list(pick_list, pick_lu_list)
}
nanal.reduce6 <- function(df, selected_var = NA, var_tail = NA, pick_list = list(), pick_lu_list = c(), start_trg = T, orig_names = NA){
if(start_trg == T){
orig_names <- names(df)
df <- data.frame(is.na(df)*1)
}
#st1 <- proc.time()
if(is.na(selected_var)){
df_reduced <- df
select_var_cut <- 0
}else{
df_reduced <- df[df[, selected_var]==0,]
select_var_cut <- selected_var
}
#stp1 <- proc.time() - st1
#strk1 <<- strk1 + stp1[3]
# Reduce dataframe to eliminate columns with the same NA locations
if(nrow(df_reduced) > 0){
if(sum(df_reduced) > 0){
#st2 <- proc.time()
dups <- which(!duplicated(apply(df_reduced, 2, digest)))
dup_names <- names(df_reduced)[dups]
# subset dups to avoid repeat scenarios
sub_dups <- dups[which(dups > select_var_cut)]
sub_dup_names <- names(df_reduced)[sub_dups]
#stp2 <- proc.time() - st2
#strk2 <<- strk2 + stp2[3]
#st3 <- proc.time()
df_reduced <- data.frame(df_reduced[,dups])
#message("reduced df number of columns ", ncol(df_reduced))
#message("reduced df number of rows ", nrow(df_reduced))
names(df_reduced) <- dup_names
# Get list of new available selections
new_pick_idx <- which(colSums(df_reduced)>0)
new_pick_names <- names(df_reduced)[new_pick_idx]
# Subset new picks to only include sub_dup indices
sub_pick_idx <- which(new_pick_names %in% sub_dup_names)
new_pick_names <- new_pick_names[sub_pick_idx]
new_pick_idx <- new_pick_idx[sub_pick_idx]
#stp3 <- proc.time() - st3
#strk3 <<- strk3 + stp3[3]
#st4 <- proc.time()
orig_pick_idx <- which(orig_names %in% new_pick_names)
# Add new selections to tail selections
#stp4 <- proc.time() - st4
#strk4 <<- strk4 + stp4[3]
#st5 <- proc.time()
pick_adds <- mapply(function(x){list(sort(c(var_tail, x)))},orig_pick_idx)
pick_lu <- mapply(function(x){paste(sort(c(var_tail, x)), collapse = '')},orig_pick_idx)
#pick_lu <- mapply(function(x){paste(sort(c(var_tail, x)), collapse = '')},orig_pick_idx)
# Check for selections which already exist
#stp5 <- proc.time() - st5
#strk5 <<- strk5 + stp5[3]
#st6 <- proc.time()
#ignore_idx <- which(pick_lu %in% pick_lu_list)
#if(length(ignore_idx) > 0){
#    pick_adds <- pick_adds[-ignore_idx]
#    new_pick_idx <- new_pick_idx[-ignore_idx]
#    pick_lu <- pick_lu[-ignore_idx]
#}
#stp6 <<- proc.time() - st6
#strk6 <<- strk6 + stp6[3]
# Print out intermmediate timing results
#lpl <- length(pick_list)
#if(lpl > ch){
#    message("Pick list length is around ", lpl)
#    message("Time 1 is ", strk1)
#    message("Time 2 is ", strk2)
#    message("Time 3 is ", strk3)
#    message("Time 4 is ", strk4)
#    message("Time 5 is ", strk5)
#    message("Time 6 is ", strk6)
#    message("Time 7 is ", strk7)
#    message("Time 8 is ", strk8)
#    message('')
#   ch <<- ch + 2500
#}
# Add unique new selections to pick list
if(length(pick_adds) > 0){
#st7 <- proc.time()
pick_list <- c(pick_list, pick_adds)
#stp7 <- proc.time() - st7
#strk7 <<- strk7 + stp7[3]
#st8 <- proc.time()
#pick_lu_list <- union(pick_lu_list, pick_lu)
pick_lu_list <- c(pick_lu_list, pick_lu)
#pick_lu_list <- pick_lu_list +
#stp8 <- proc.time() - st8
#strk8 <<- strk8 + stp8[3]
# For remaining new picks, rerun function
#foreach(idx = 1:length(pick_adds), .packages = 'digest') %dopar% {
for(idx in 1:length(pick_adds)){
result <- nanal.reduce6(df_reduced, new_pick_idx[idx], pick_adds[[idx]], pick_list, pick_lu_list, F, orig_names)
pick_list <- result[[1]]
pick_lu_list <- result[[2]]
}
}
}
}
list(pick_list, pick_lu_list)
}
df_test_reduce_list_6 <- nanal.reduce6(df_test)[[1]]
df_test_na_scores_6 <- nanal.score(df_test, df_test_reduce_list_6, 10)
df <- df_test
red_4 <- proc.time()
red_4_list <- nanal.reduce4(df)[[1]]
red_4 <- proc.time() - red_4
red_5 <- proc.time()
red_5_list <- nanal.reduce5(df)[[1]]
red_5 <- proc.time() - red_5
red_6 <- proc.time()
red_6_list <- nanal.reduce6(df)[[1]]
red_6 <- proc.time() - red_6
#message('version 1 time: ', t2[3])
message('version 4 time: ', red_4[3])
message('version 5 time: ', red_5[3])
message('version 6 time: ', red_6[3])
identical(df_test_na_scores_5, df_test_na_scores_6)
df <- df_golf[,c(1:100)]
df_golf <- read.csv('Golf/Data/combined/Model Data/Masters/Model Data/master_model_data.csv', header = T, stringsAsFactors = F)
lo_list <- c('PLAYER_NAME', 'year', 'previous_year.x', 'previous_year.y')
lo_list <- which(lo_list %in% names(df_golf))
df_golf <- df_golf[,-lo_list]
df <- df_golf[,c(1:100)]
red_5_list <- nanal.reduce5(df)[[1]]
red_6_list <- nanal.reduce6(df)[[1]]
red_5_list
red_4_list
red_4 <- proc.time()
red_4_list <- nanal.reduce4(df)[[1]]
red_4 <- proc.time() - red_4
red_5 <- proc.time()
red_5_list <- nanal.reduce5(df)[[1]]
red_5 <- proc.time() - red_5
red_6 <- proc.time()
red_6_list <- nanal.reduce6(df)[[1]]
red_6 <- proc.time() - red_6
#message('version 1 time: ', t2[3])
message('version 4 time: ', red_4[3])
message('version 5 time: ', red_5[3])
message('version 6 time: ', red_6[3])
df <- df_golf[,c(1:150)]
red_4 <- proc.time()
red_4_list <- nanal.reduce4(df)[[1]]
red_4 <- proc.time() - red_4
red_5 <- proc.time()
red_5_list <- nanal.reduce5(df)[[1]]
red_5 <- proc.time() - red_5
red_6 <- proc.time()
red_6_list <- nanal.reduce6(df)[[1]]
red_6 <- proc.time() - red_6
#message('version 1 time: ', t2[3])
message('version 4 time: ', red_4[3])
message('version 5 time: ', red_5[3])
message('version 6 time: ', red_6[3])
red_6_list
df <- df_golf[,c(1:200)]
red_5 <- proc.time()
red_5_list <- nanal.reduce5(df)[[1]]
red_5 <- proc.time() - red_5
red_6 <- proc.time()
red_6_list <- nanal.reduce6(df)[[1]]
red_6 <- proc.time() - red_6
#message('version 1 time: ', t2[3])
message('version 4 time: ', red_4[3])
message('version 5 time: ', red_5[3])
message('version 6 time: ', red_6[3])
df <- df_golf[,c(1:250)]
red_5 <- proc.time()
red_5_list <- nanal.reduce5(df)[[1]]
red_5 <- proc.time() - red_5
red_6 <- proc.time()
red_6_list <- nanal.reduce6(df)[[1]]
red_6 <- proc.time() - red_6
#message('version 1 time: ', t2[3])
message('version 4 time: ', red_4[3])
message('version 5 time: ', red_5[3])
message('version 6 time: ', red_6[3])
identical(red_5_list, red_6_list)
df <- df_golf[,c(1:300)]
df <- df_golf[,c(1:350)]
red_5 <- proc.time()
red_5_list <- nanal.reduce5(df)[[1]]
red_5 <- proc.time() - red_5
red_6 <- proc.time()
red_6_list <- nanal.reduce6(df)[[1]]
red_6 <- proc.time() - red_6
#message('version 1 time: ', t2[3])
message('version 4 time: ', red_4[3])
message('version 5 time: ', red_5[3])
message('version 6 time: ', red_6[3])
df <- df_golf
gc()
red_6 <- proc.time()
red_6_list <- nanal.reduce6(df)[[1]]
library(RMySQL)
library(gtools)
library(stringr)
library(R.utils)
library(dplyr)
library(ggplot2)
ls('gtools')
ls('package;gtools')
ls('package:gtools')
ls('package:R.utils')
setwd('Boomer Pool')
library(shiny)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
